---------------------------------------------------------------------------
Training stage 0
Sampled 12249 windows from 32077 images.
Done sampling windows (time=343s).
Extracting features... done (time=5s).
Computing correlations... done (time=4s).
Computing lambdas... done (time=34s).
Extracting features... done (time=16s).
Sampled 25000 windows from 1024 images.
Done sampling windows (time=18s).
Extracting features... done (time=17s).
Training AdaBoost: nWeak= 64 nFtrs=5120 pos=24498 neg=25000
 i=  16 alpha=1.000 err=0.215 loss=8.50e-03
 i=  32 alpha=1.000 err=0.207 loss=2.15e-04
 i=  48 alpha=1.000 err=0.217 loss=6.23e-06
 i=  64 alpha=1.000 err=0.247 loss=1.67e-07
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=7.3s).
Done training stage 0 (time=445s).
---------------------------------------------------------------------------
Training stage 1
Sampled 25000 windows from 1216 images.
Done sampling windows (time=74s).
Extracting features... done (time=17s).
Training AdaBoost: nWeak=256 nFtrs=5120 pos=24498 neg=50000
 i=  16 alpha=1.000 err=0.353 loss=2.85e-01
 i=  32 alpha=1.000 err=0.378 loss=1.41e-01
 i=  48 alpha=1.000 err=0.364 loss=7.07e-02
 i=  64 alpha=1.000 err=0.385 loss=3.67e-02
 i=  80 alpha=1.000 err=0.369 loss=1.84e-02
 i=  96 alpha=1.000 err=0.361 loss=8.99e-03
 i= 112 alpha=1.000 err=0.369 loss=4.60e-03
 i= 128 alpha=1.000 err=0.381 loss=2.37e-03
 i= 144 alpha=1.000 err=0.354 loss=1.18e-03
 i= 160 alpha=1.000 err=0.367 loss=5.89e-04
 i= 176 alpha=1.000 err=0.365 loss=2.94e-04
 i= 192 alpha=1.000 err=0.370 loss=1.45e-04
 i= 208 alpha=1.000 err=0.366 loss=7.07e-05
 i= 224 alpha=1.000 err=0.364 loss=3.43e-05
 i= 240 alpha=1.000 err=0.364 loss=1.68e-05
 i= 256 alpha=1.000 err=0.338 loss=8.26e-06
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=30.6s).
Done training stage 1 (time=123s).
---------------------------------------------------------------------------
Training stage 2
Sampled 25000 windows from 3776 images.
Done sampling windows (time=223s).
Extracting features... done (time=16s).
Training AdaBoost: nWeak=1024 nFtrs=5120 pos=24498 neg=50000
 i=  16 alpha=1.000 err=0.380 loss=4.20e-01
 i=  32 alpha=1.000 err=0.392 loss=2.51e-01
 i=  48 alpha=1.000 err=0.402 loss=1.55e-01
 i=  64 alpha=1.000 err=0.396 loss=9.46e-02
 i=  80 alpha=1.000 err=0.393 loss=5.98e-02
 i=  96 alpha=1.000 err=0.382 loss=3.67e-02
 i= 112 alpha=1.000 err=0.398 loss=2.29e-02
 i= 128 alpha=1.000 err=0.390 loss=1.40e-02
 i= 144 alpha=1.000 err=0.395 loss=8.62e-03
 i= 160 alpha=1.000 err=0.391 loss=5.30e-03
 i= 176 alpha=1.000 err=0.387 loss=3.18e-03
 i= 192 alpha=1.000 err=0.390 loss=1.96e-03
 i= 208 alpha=1.000 err=0.395 loss=1.18e-03
 i= 224 alpha=1.000 err=0.385 loss=7.21e-04
 i= 240 alpha=1.000 err=0.396 loss=4.37e-04
 i= 256 alpha=1.000 err=0.378 loss=2.60e-04
 i= 272 alpha=1.000 err=0.394 loss=1.55e-04
 i= 288 alpha=1.000 err=0.390 loss=9.39e-05
 i= 304 alpha=1.000 err=0.392 loss=5.74e-05
 i= 320 alpha=1.000 err=0.388 loss=3.46e-05
 i= 336 alpha=1.000 err=0.382 loss=2.09e-05
 i= 352 alpha=1.000 err=0.384 loss=1.27e-05
 i= 368 alpha=1.000 err=0.391 loss=7.52e-06
 i= 384 alpha=1.000 err=0.384 loss=4.66e-06
 i= 400 alpha=1.000 err=0.382 loss=2.79e-06
 i= 416 alpha=1.000 err=0.378 loss=1.69e-06
 i= 432 alpha=1.000 err=0.395 loss=1.04e-06
 i= 448 alpha=1.000 err=0.395 loss=6.30e-07
 i= 464 alpha=1.000 err=0.383 loss=3.81e-07
 i= 480 alpha=1.000 err=0.391 loss=2.32e-07
 i= 496 alpha=1.000 err=0.395 loss=1.40e-07
 i= 512 alpha=1.000 err=0.394 loss=8.54e-08
 i= 528 alpha=1.000 err=0.386 loss=5.10e-08
 i= 544 alpha=1.000 err=0.379 loss=3.07e-08
 i= 560 alpha=1.000 err=0.394 loss=1.86e-08
 i= 576 alpha=1.000 err=0.384 loss=1.12e-08
 i= 592 alpha=1.000 err=0.379 loss=6.71e-09
 i= 608 alpha=1.000 err=0.374 loss=3.92e-09
 i= 624 alpha=1.000 err=0.387 loss=2.35e-09
 i= 640 alpha=1.000 err=0.379 loss=1.41e-09
 i= 656 alpha=1.000 err=0.388 loss=8.62e-10
 i= 672 alpha=1.000 err=0.376 loss=5.10e-10
 i= 688 alpha=1.000 err=0.401 loss=3.07e-10
 i= 704 alpha=1.000 err=0.388 loss=1.84e-10
 i= 720 alpha=1.000 err=0.389 loss=1.10e-10
 i= 736 alpha=1.000 err=0.379 loss=6.55e-11
 i= 752 alpha=1.000 err=0.394 loss=3.91e-11
 i= 768 alpha=1.000 err=0.386 loss=2.31e-11
 i= 784 alpha=1.000 err=0.380 loss=1.39e-11
 i= 800 alpha=1.000 err=0.378 loss=8.28e-12
 i= 816 alpha=1.000 err=0.379 loss=4.96e-12
 i= 832 alpha=1.000 err=0.385 loss=2.94e-12
 i= 848 alpha=1.000 err=0.387 loss=1.75e-12
 i= 864 alpha=1.000 err=0.390 loss=1.06e-12
 i= 880 alpha=1.000 err=0.392 loss=6.37e-13
 i= 896 alpha=1.000 err=0.392 loss=3.83e-13
 i= 912 alpha=1.000 err=0.382 loss=2.30e-13
 i= 928 alpha=1.000 err=0.396 loss=1.37e-13
 i= 944 alpha=1.000 err=0.386 loss=8.18e-14
 i= 960 alpha=1.000 err=0.385 loss=4.85e-14
 i= 976 alpha=1.000 err=0.389 loss=2.94e-14
 i= 992 alpha=1.000 err=0.378 loss=1.74e-14
 i=1008 alpha=1.000 err=0.391 loss=1.02e-14
 i=1024 alpha=1.000 err=0.378 loss=5.84e-15
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=129.3s).
Done training stage 2 (time=371s).
---------------------------------------------------------------------------
Training stage 3
Sampled 14913 windows from 32077 images.
Done sampling windows (time=1690s).
Extracting features... done (time=8s).
Training AdaBoost: nWeak=4096 nFtrs=5120 pos=24498 neg=50000
 i=  16 alpha=1.000 err=0.391 loss=5.55e-01
 i=  32 alpha=1.000 err=0.421 loss=3.95e-01
 i=  48 alpha=1.000 err=0.401 loss=2.83e-01
 i=  64 alpha=1.000 err=0.408 loss=2.03e-01
 i=  80 alpha=1.000 err=0.424 loss=1.46e-01
 i=  96 alpha=1.000 err=0.408 loss=1.03e-01
 i= 112 alpha=1.000 err=0.407 loss=7.39e-02
 i= 128 alpha=1.000 err=0.404 loss=5.19e-02
 i= 144 alpha=1.000 err=0.408 loss=3.62e-02
 i= 160 alpha=1.000 err=0.410 loss=2.56e-02
 i= 176 alpha=1.000 err=0.404 loss=1.83e-02
 i= 192 alpha=1.000 err=0.403 loss=1.29e-02
 i= 208 alpha=1.000 err=0.412 loss=9.03e-03
 i= 224 alpha=1.000 err=0.407 loss=6.26e-03
 i= 240 alpha=1.000 err=0.401 loss=4.39e-03
 i= 256 alpha=1.000 err=0.414 loss=3.16e-03
 i= 272 alpha=1.000 err=0.414 loss=2.21e-03
 i= 288 alpha=1.000 err=0.405 loss=1.57e-03
 i= 304 alpha=1.000 err=0.407 loss=1.10e-03
 i= 320 alpha=1.000 err=0.399 loss=7.66e-04
 i= 336 alpha=1.000 err=0.407 loss=5.44e-04
 i= 352 alpha=1.000 err=0.411 loss=3.81e-04
 i= 368 alpha=1.000 err=0.408 loss=2.66e-04
 i= 384 alpha=1.000 err=0.401 loss=1.85e-04
 i= 400 alpha=1.000 err=0.408 loss=1.28e-04
 i= 416 alpha=1.000 err=0.413 loss=9.01e-05
 i= 432 alpha=1.000 err=0.401 loss=6.19e-05
 i= 448 alpha=1.000 err=0.405 loss=4.35e-05
 i= 464 alpha=1.000 err=0.405 loss=3.00e-05
 i= 480 alpha=1.000 err=0.414 loss=2.07e-05
 i= 496 alpha=1.000 err=0.405 loss=1.45e-05
 i= 512 alpha=1.000 err=0.411 loss=1.01e-05
 i= 528 alpha=1.000 err=0.399 loss=7.06e-06
 i= 544 alpha=1.000 err=0.398 loss=4.89e-06
 i= 560 alpha=1.000 err=0.406 loss=3.36e-06
 i= 576 alpha=1.000 err=0.415 loss=2.36e-06
 i= 592 alpha=1.000 err=0.403 loss=1.65e-06
 i= 608 alpha=1.000 err=0.397 loss=1.15e-06
 i= 624 alpha=1.000 err=0.406 loss=7.96e-07
 i= 640 alpha=1.000 err=0.400 loss=5.47e-07
 i= 656 alpha=1.000 err=0.410 loss=3.80e-07
 i= 672 alpha=1.000 err=0.419 loss=2.69e-07
 i= 688 alpha=1.000 err=0.404 loss=1.84e-07
 i= 704 alpha=1.000 err=0.401 loss=1.29e-07
 i= 720 alpha=1.000 err=0.402 loss=8.86e-08
 i= 736 alpha=1.000 err=0.403 loss=6.16e-08
 i= 752 alpha=1.000 err=0.394 loss=4.27e-08
 i= 768 alpha=1.000 err=0.409 loss=2.95e-08
 i= 784 alpha=1.000 err=0.404 loss=2.07e-08
 i= 800 alpha=1.000 err=0.407 loss=1.44e-08
 i= 816 alpha=1.000 err=0.403 loss=1.02e-08
 i= 832 alpha=1.000 err=0.413 loss=7.06e-09
 i= 848 alpha=1.000 err=0.406 loss=4.95e-09
 i= 864 alpha=1.000 err=0.404 loss=3.41e-09
 i= 880 alpha=1.000 err=0.406 loss=2.37e-09
 i= 896 alpha=1.000 err=0.410 loss=1.65e-09
 i= 912 alpha=1.000 err=0.405 loss=1.15e-09
 i= 928 alpha=1.000 err=0.395 loss=8.03e-10
 i= 944 alpha=1.000 err=0.406 loss=5.61e-10
 i= 960 alpha=1.000 err=0.409 loss=3.84e-10
 i= 976 alpha=1.000 err=0.406 loss=2.70e-10
 i= 992 alpha=1.000 err=0.418 loss=1.88e-10
 i=1008 alpha=1.000 err=0.406 loss=1.29e-10
 i=1024 alpha=1.000 err=0.407 loss=8.94e-11
 i=1040 alpha=1.000 err=0.410 loss=6.22e-11
 i=1056 alpha=1.000 err=0.399 loss=4.29e-11
 i=1072 alpha=1.000 err=0.405 loss=2.98e-11
 i=1088 alpha=1.000 err=0.408 loss=2.08e-11
 i=1104 alpha=1.000 err=0.392 loss=1.43e-11
 i=1120 alpha=1.000 err=0.397 loss=9.80e-12
 i=1136 alpha=1.000 err=0.416 loss=6.88e-12
 i=1152 alpha=1.000 err=0.410 loss=4.77e-12
 i=1168 alpha=1.000 err=0.408 loss=3.31e-12
 i=1184 alpha=1.000 err=0.402 loss=2.30e-12
 i=1200 alpha=1.000 err=0.411 loss=1.61e-12
 i=1216 alpha=1.000 err=0.400 loss=1.11e-12
 i=1232 alpha=1.000 err=0.410 loss=7.54e-13
 i=1248 alpha=1.000 err=0.403 loss=5.19e-13
 i=1264 alpha=1.000 err=0.400 loss=3.51e-13
 i=1280 alpha=1.000 err=0.397 loss=2.43e-13
 i=1296 alpha=1.000 err=0.392 loss=1.67e-13
 i=1312 alpha=1.000 err=0.396 loss=1.14e-13
 i=1328 alpha=1.000 err=0.401 loss=7.92e-14
 i=1344 alpha=1.000 err=0.405 loss=5.51e-14
 i=1360 alpha=1.000 err=0.392 loss=3.80e-14
 i=1376 alpha=1.000 err=0.400 loss=2.63e-14
 i=1392 alpha=1.000 err=0.410 loss=1.82e-14
 i=1408 alpha=1.000 err=0.403 loss=1.26e-14
 i=1424 alpha=1.000 err=0.412 loss=8.81e-15
 i=1440 alpha=1.000 err=0.411 loss=6.02e-15
 i=1456 alpha=1.000 err=0.399 loss=4.13e-15
 i=1472 alpha=1.000 err=0.406 loss=2.88e-15
 i=1488 alpha=1.000 err=0.408 loss=2.02e-15
 i=1504 alpha=1.000 err=0.403 loss=1.40e-15
 i=1520 alpha=1.000 err=0.417 loss=9.72e-16
 i=1536 alpha=1.000 err=0.412 loss=6.74e-16
 i=1552 alpha=1.000 err=0.403 loss=4.70e-16
 i=1568 alpha=1.000 err=0.399 loss=3.21e-16
 i=1584 alpha=1.000 err=0.408 loss=2.24e-16
 i=1600 alpha=1.000 err=0.405 loss=1.57e-16
 i=1616 alpha=1.000 err=0.406 loss=1.08e-16
 i=1632 alpha=1.000 err=0.419 loss=7.51e-17
 i=1648 alpha=1.000 err=0.401 loss=5.17e-17
 i=1664 alpha=1.000 err=0.399 loss=3.55e-17
 i=1680 alpha=1.000 err=0.406 loss=2.48e-17
 i=1696 alpha=1.000 err=0.404 loss=1.72e-17
 i=1712 alpha=1.000 err=0.400 loss=1.19e-17
 i=1728 alpha=1.000 err=0.408 loss=8.27e-18
 i=1744 alpha=1.000 err=0.392 loss=5.70e-18
 i=1760 alpha=1.000 err=0.409 loss=3.89e-18
 i=1776 alpha=1.000 err=0.402 loss=2.69e-18
 i=1792 alpha=1.000 err=0.405 loss=1.86e-18
 i=1808 alpha=1.000 err=0.402 loss=1.29e-18
 i=1824 alpha=1.000 err=0.409 loss=8.96e-19
 i=1840 alpha=1.000 err=0.409 loss=6.21e-19
 i=1856 alpha=1.000 err=0.400 loss=4.23e-19
 i=1872 alpha=1.000 err=0.410 loss=2.93e-19
 i=1888 alpha=1.000 err=0.403 loss=2.00e-19
 i=1904 alpha=1.000 err=0.414 loss=1.39e-19
 i=1920 alpha=1.000 err=0.403 loss=9.69e-20
 i=1936 alpha=1.000 err=0.398 loss=6.73e-20
 i=1952 alpha=1.000 err=0.406 loss=4.67e-20
 i=1968 alpha=1.000 err=0.406 loss=3.26e-20
 i=1984 alpha=1.000 err=0.400 loss=2.28e-20
 i=2000 alpha=1.000 err=0.409 loss=1.58e-20
 i=2016 alpha=1.000 err=0.398 loss=1.10e-20
 i=2032 alpha=1.000 err=0.401 loss=7.77e-21
 i=2048 alpha=1.000 err=0.403 loss=5.32e-21
 i=2064 alpha=1.000 err=0.407 loss=3.72e-21
 i=2080 alpha=1.000 err=0.403 loss=2.55e-21
 i=2096 alpha=1.000 err=0.412 loss=1.77e-21
 i=2112 alpha=1.000 err=0.404 loss=1.21e-21
 i=2128 alpha=1.000 err=0.408 loss=8.53e-22
 i=2144 alpha=1.000 err=0.404 loss=5.81e-22
 i=2160 alpha=1.000 err=0.403 loss=4.05e-22
 i=2176 alpha=1.000 err=0.411 loss=2.84e-22
 i=2192 alpha=1.000 err=0.403 loss=1.99e-22
 i=2208 alpha=1.000 err=0.404 loss=1.37e-22
 i=2224 alpha=1.000 err=0.409 loss=9.45e-23
 i=2240 alpha=1.000 err=0.417 loss=6.50e-23
 i=2256 alpha=1.000 err=0.402 loss=4.52e-23
 i=2272 alpha=1.000 err=0.411 loss=3.09e-23
 i=2288 alpha=1.000 err=0.421 loss=2.12e-23
 i=2304 alpha=1.000 err=0.390 loss=1.45e-23
 i=2320 alpha=1.000 err=0.411 loss=1.01e-23
 i=2336 alpha=1.000 err=0.405 loss=6.97e-24
 i=2352 alpha=1.000 err=0.407 loss=4.89e-24
 i=2368 alpha=1.000 err=0.406 loss=3.36e-24
 i=2384 alpha=1.000 err=0.409 loss=2.34e-24
 i=2400 alpha=1.000 err=0.412 loss=1.66e-24
 i=2416 alpha=1.000 err=0.406 loss=1.15e-24
 i=2432 alpha=1.000 err=0.401 loss=8.02e-25
 i=2448 alpha=1.000 err=0.406 loss=5.59e-25
 i=2464 alpha=1.000 err=0.401 loss=3.86e-25
 i=2480 alpha=1.000 err=0.399 loss=2.70e-25
 i=2496 alpha=1.000 err=0.407 loss=1.88e-25
 i=2512 alpha=1.000 err=0.402 loss=1.30e-25
 i=2528 alpha=1.000 err=0.408 loss=8.88e-26
 i=2544 alpha=1.000 err=0.399 loss=6.20e-26
 i=2560 alpha=1.000 err=0.411 loss=4.31e-26
 i=2576 alpha=1.000 err=0.406 loss=3.02e-26
 i=2592 alpha=1.000 err=0.415 loss=2.11e-26
 i=2608 alpha=1.000 err=0.414 loss=1.45e-26
 i=2624 alpha=1.000 err=0.401 loss=1.01e-26
 i=2640 alpha=1.000 err=0.403 loss=7.10e-27
 i=2656 alpha=1.000 err=0.403 loss=4.85e-27
 i=2672 alpha=1.000 err=0.405 loss=3.36e-27
 i=2688 alpha=1.000 err=0.405 loss=2.30e-27
 i=2704 alpha=1.000 err=0.407 loss=1.60e-27
 i=2720 alpha=1.000 err=0.410 loss=1.12e-27
 i=2736 alpha=1.000 err=0.405 loss=7.82e-28
 i=2752 alpha=1.000 err=0.403 loss=5.41e-28
 i=2768 alpha=1.000 err=0.401 loss=3.74e-28
 i=2784 alpha=1.000 err=0.410 loss=2.61e-28
 i=2800 alpha=1.000 err=0.401 loss=1.80e-28
 i=2816 alpha=1.000 err=0.406 loss=1.24e-28
 i=2832 alpha=1.000 err=0.400 loss=8.66e-29
 i=2848 alpha=1.000 err=0.402 loss=5.95e-29
 i=2864 alpha=1.000 err=0.408 loss=4.12e-29
 i=2880 alpha=1.000 err=0.408 loss=2.87e-29
 i=2896 alpha=1.000 err=0.413 loss=1.99e-29
 i=2912 alpha=1.000 err=0.402 loss=1.40e-29
 i=2928 alpha=1.000 err=0.402 loss=9.67e-30
 i=2944 alpha=1.000 err=0.411 loss=6.71e-30
 i=2960 alpha=1.000 err=0.402 loss=4.67e-30
 i=2976 alpha=1.000 err=0.406 loss=3.24e-30
 i=2992 alpha=1.000 err=0.398 loss=2.28e-30
 i=3008 alpha=1.000 err=0.396 loss=1.57e-30
 i=3024 alpha=1.000 err=0.403 loss=1.08e-30
 i=3040 alpha=1.000 err=0.419 loss=7.63e-31
 i=3056 alpha=1.000 err=0.394 loss=5.23e-31
 i=3072 alpha=1.000 err=0.419 loss=3.64e-31
 i=3088 alpha=1.000 err=0.408 loss=2.53e-31
 i=3104 alpha=1.000 err=0.414 loss=1.76e-31
 i=3120 alpha=1.000 err=0.414 loss=1.22e-31
 i=3136 alpha=1.000 err=0.406 loss=8.50e-32
 i=3152 alpha=1.000 err=0.411 loss=5.89e-32
 i=3168 alpha=1.000 err=0.419 loss=4.15e-32
 i=3184 alpha=1.000 err=0.399 loss=2.88e-32
 i=3200 alpha=1.000 err=0.406 loss=2.04e-32
 i=3216 alpha=1.000 err=0.403 loss=1.43e-32
 i=3232 alpha=1.000 err=0.405 loss=9.98e-33
 i=3248 alpha=1.000 err=0.395 loss=6.81e-33
 i=3264 alpha=1.000 err=0.407 loss=4.73e-33
 i=3280 alpha=1.000 err=0.406 loss=3.31e-33
 i=3296 alpha=1.000 err=0.417 loss=2.33e-33
 i=3312 alpha=1.000 err=0.400 loss=1.61e-33
 i=3328 alpha=1.000 err=0.400 loss=1.11e-33
 i=3344 alpha=1.000 err=0.407 loss=7.69e-34
 i=3360 alpha=1.000 err=0.408 loss=5.37e-34
 i=3376 alpha=1.000 err=0.395 loss=3.63e-34
 i=3392 alpha=1.000 err=0.402 loss=2.48e-34
 i=3408 alpha=1.000 err=0.393 loss=1.73e-34
 i=3424 alpha=1.000 err=0.411 loss=1.21e-34
 i=3440 alpha=1.000 err=0.419 loss=8.49e-35
 i=3456 alpha=1.000 err=0.399 loss=5.83e-35
 i=3472 alpha=1.000 err=0.406 loss=4.06e-35
 i=3488 alpha=1.000 err=0.406 loss=2.82e-35
 i=3504 alpha=1.000 err=0.414 loss=1.97e-35
 i=3520 alpha=1.000 err=0.402 loss=1.35e-35
 i=3536 alpha=1.000 err=0.406 loss=9.25e-36
 i=3552 alpha=1.000 err=0.402 loss=6.42e-36
 i=3568 alpha=1.000 err=0.403 loss=4.42e-36
 i=3584 alpha=1.000 err=0.398 loss=3.03e-36
 i=3600 alpha=1.000 err=0.405 loss=2.04e-36
 i=3616 alpha=1.000 err=0.404 loss=1.41e-36
 i=3632 alpha=1.000 err=0.409 loss=9.90e-37
 i=3648 alpha=1.000 err=0.413 loss=6.80e-37
 i=3664 alpha=1.000 err=0.406 loss=4.69e-37
 i=3680 alpha=1.000 err=0.417 loss=3.23e-37
 i=3696 alpha=1.000 err=0.403 loss=2.24e-37
 i=3712 alpha=1.000 err=0.399 loss=1.53e-37
 i=3728 alpha=1.000 err=0.409 loss=1.05e-37
 i=3744 alpha=1.000 err=0.401 loss=7.25e-38
 i=3760 alpha=1.000 err=0.406 loss=5.04e-38
 i=3776 alpha=1.000 err=0.408 loss=3.48e-38
 i=3792 alpha=1.000 err=0.412 loss=2.38e-38
 i=3808 alpha=1.000 err=0.402 loss=1.65e-38
 i=3824 alpha=1.000 err=0.405 loss=1.13e-38
 i=3840 alpha=1.000 err=0.399 loss=7.79e-39
 i=3856 alpha=1.000 err=0.407 loss=5.34e-39
 i=3872 alpha=1.000 err=0.414 loss=3.68e-39
 i=3888 alpha=1.000 err=0.412 loss=2.58e-39
 i=3904 alpha=1.000 err=0.407 loss=1.79e-39
 i=3920 alpha=1.000 err=0.402 loss=1.23e-39
 i=3936 alpha=1.000 err=0.406 loss=8.54e-40
 i=3952 alpha=1.000 err=0.403 loss=5.90e-40
 i=3968 alpha=1.000 err=0.402 loss=4.10e-40
 i=3984 alpha=1.000 err=0.402 loss=2.82e-40
 i=4000 alpha=1.000 err=0.398 loss=1.93e-40
 i=4016 alpha=1.000 err=0.404 loss=1.32e-40
 stopping early
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=370.5s).
Done training stage 3 (time=2071s).
---------------------------------------------------------------------------
Done training (time=3011s).
