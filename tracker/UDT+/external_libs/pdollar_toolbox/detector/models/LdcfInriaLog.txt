---------------------------------------------------------------------------
Training stage 0
Sampled 1237 windows from 614 images.
Done sampling windows (time=14s).
Extracting features... done (time=1s).
Computing correlations... done (time=2s).
Computing lambdas... done (time=4s).
Extracting features... done (time=23s).
Sampled 5000 windows from 256 images.
Done sampling windows (time=2s).
Extracting features... done (time=4s).
Training AdaBoost: nWeak= 32 nFtrs=20480 pos=22266 neg=5000
 i=  16 alpha=1.000 err=0.219 loss=1.47e-02
 i=  32 alpha=1.000 err=0.214 loss=5.21e-04
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=4.6s).
Done training stage 0 (time=58s).
---------------------------------------------------------------------------
Training stage 1
Sampled 5000 windows from 448 images.
Done sampling windows (time=12s).
Extracting features... done (time=4s).
Training AdaBoost: nWeak=128 nFtrs=20480 pos=22266 neg=10000
 i=  16 alpha=1.000 err=0.303 loss=1.39e-01
 i=  32 alpha=1.000 err=0.317 loss=3.75e-02
 i=  48 alpha=1.000 err=0.314 loss=1.06e-02
 i=  64 alpha=1.000 err=0.320 loss=2.85e-03
 i=  80 alpha=1.000 err=0.315 loss=7.66e-04
 i=  96 alpha=1.000 err=0.311 loss=2.04e-04
 i= 112 alpha=1.000 err=0.311 loss=5.55e-05
 i= 128 alpha=1.000 err=0.298 loss=1.49e-05
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=8.5s).
Done training stage 1 (time=26s).
---------------------------------------------------------------------------
Training stage 2
Sampled 2253 windows from 1218 images.
Done sampling windows (time=30s).
Extracting features... done (time=2s).
Training AdaBoost: nWeak=512 nFtrs=20480 pos=22266 neg=10000
 i=  16 alpha=1.000 err=0.343 loss=2.22e-01
 i=  32 alpha=1.000 err=0.341 loss=8.18e-02
 i=  48 alpha=1.000 err=0.344 loss=3.20e-02
 i=  64 alpha=1.000 err=0.344 loss=1.22e-02
 i=  80 alpha=1.000 err=0.331 loss=4.54e-03
 i=  96 alpha=1.000 err=0.329 loss=1.70e-03
 i= 112 alpha=1.000 err=0.330 loss=6.32e-04
 i= 128 alpha=1.000 err=0.328 loss=2.34e-04
 i= 144 alpha=1.000 err=0.351 loss=8.78e-05
 i= 160 alpha=1.000 err=0.332 loss=3.43e-05
 i= 176 alpha=1.000 err=0.340 loss=1.30e-05
 i= 192 alpha=1.000 err=0.345 loss=4.92e-06
 i= 208 alpha=1.000 err=0.337 loss=1.85e-06
 i= 224 alpha=1.000 err=0.344 loss=7.08e-07
 i= 240 alpha=1.000 err=0.336 loss=2.69e-07
 i= 256 alpha=1.000 err=0.332 loss=1.04e-07
 i= 272 alpha=1.000 err=0.345 loss=3.88e-08
 i= 288 alpha=1.000 err=0.334 loss=1.44e-08
 i= 304 alpha=1.000 err=0.346 loss=5.48e-09
 i= 320 alpha=1.000 err=0.341 loss=2.16e-09
 i= 336 alpha=1.000 err=0.340 loss=7.98e-10
 i= 352 alpha=1.000 err=0.333 loss=2.94e-10
 i= 368 alpha=1.000 err=0.344 loss=1.12e-10
 i= 384 alpha=1.000 err=0.333 loss=4.43e-11
 i= 400 alpha=1.000 err=0.350 loss=1.70e-11
 i= 416 alpha=1.000 err=0.335 loss=6.39e-12
 i= 432 alpha=1.000 err=0.338 loss=2.42e-12
 i= 448 alpha=1.000 err=0.327 loss=9.13e-13
 i= 464 alpha=1.000 err=0.333 loss=3.33e-13
 i= 480 alpha=1.000 err=0.341 loss=1.22e-13
 i= 496 alpha=1.000 err=0.339 loss=4.63e-14
 i= 512 alpha=1.000 err=0.343 loss=1.73e-14
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=21.3s).
Done training stage 2 (time=55s).
---------------------------------------------------------------------------
Training stage 3
Sampled 164 windows from 1218 images.
Done sampling windows (time=31s).
Extracting features... done (time=0s).
Training AdaBoost: nWeak=2048 nFtrs=20480 pos=22266 neg=10000
 i=  16 alpha=1.000 err=0.336 loss=2.27e-01
 i=  32 alpha=1.000 err=0.333 loss=8.54e-02
 i=  48 alpha=1.000 err=0.351 loss=3.43e-02
 i=  64 alpha=1.000 err=0.334 loss=1.36e-02
 i=  80 alpha=1.000 err=0.340 loss=5.48e-03
 i=  96 alpha=1.000 err=0.346 loss=2.22e-03
 i= 112 alpha=1.000 err=0.344 loss=8.95e-04
 i= 128 alpha=1.000 err=0.348 loss=3.62e-04
 i= 144 alpha=1.000 err=0.344 loss=1.49e-04
 i= 160 alpha=1.000 err=0.338 loss=5.92e-05
 i= 176 alpha=1.000 err=0.350 loss=2.37e-05
 i= 192 alpha=1.000 err=0.341 loss=9.51e-06
 i= 208 alpha=1.000 err=0.346 loss=3.78e-06
 i= 224 alpha=1.000 err=0.341 loss=1.48e-06
 i= 240 alpha=1.000 err=0.347 loss=5.78e-07
 i= 256 alpha=1.000 err=0.344 loss=2.32e-07
 i= 272 alpha=1.000 err=0.339 loss=9.27e-08
 i= 288 alpha=1.000 err=0.343 loss=3.81e-08
 i= 304 alpha=1.000 err=0.353 loss=1.53e-08
 i= 320 alpha=1.000 err=0.340 loss=5.94e-09
 i= 336 alpha=1.000 err=0.336 loss=2.36e-09
 i= 352 alpha=1.000 err=0.341 loss=8.97e-10
 i= 368 alpha=1.000 err=0.338 loss=3.40e-10
 i= 384 alpha=1.000 err=0.349 loss=1.37e-10
 i= 400 alpha=1.000 err=0.350 loss=5.38e-11
 i= 416 alpha=1.000 err=0.340 loss=2.05e-11
 i= 432 alpha=1.000 err=0.347 loss=8.10e-12
 i= 448 alpha=1.000 err=0.344 loss=3.30e-12
 i= 464 alpha=1.000 err=0.336 loss=1.30e-12
 i= 480 alpha=1.000 err=0.349 loss=5.10e-13
 i= 496 alpha=1.000 err=0.353 loss=2.02e-13
 i= 512 alpha=1.000 err=0.353 loss=7.56e-14
 i= 528 alpha=1.000 err=0.346 loss=3.03e-14
 i= 544 alpha=1.000 err=0.353 loss=1.20e-14
 i= 560 alpha=1.000 err=0.351 loss=4.84e-15
 i= 576 alpha=1.000 err=0.339 loss=1.94e-15
 i= 592 alpha=1.000 err=0.340 loss=7.43e-16
 i= 608 alpha=1.000 err=0.335 loss=2.94e-16
 i= 624 alpha=1.000 err=0.332 loss=1.08e-16
 i= 640 alpha=1.000 err=0.335 loss=4.10e-17
 i= 656 alpha=1.000 err=0.349 loss=1.62e-17
 i= 672 alpha=1.000 err=0.352 loss=6.46e-18
 i= 688 alpha=1.000 err=0.331 loss=2.54e-18
 i= 704 alpha=1.000 err=0.350 loss=9.99e-19
 i= 720 alpha=1.000 err=0.341 loss=3.82e-19
 i= 736 alpha=1.000 err=0.337 loss=1.51e-19
 i= 752 alpha=1.000 err=0.325 loss=6.00e-20
 i= 768 alpha=1.000 err=0.342 loss=2.40e-20
 i= 784 alpha=1.000 err=0.340 loss=9.18e-21
 i= 800 alpha=1.000 err=0.334 loss=3.61e-21
 i= 816 alpha=1.000 err=0.352 loss=1.36e-21
 i= 832 alpha=1.000 err=0.338 loss=5.19e-22
 i= 848 alpha=1.000 err=0.344 loss=2.03e-22
 i= 864 alpha=1.000 err=0.338 loss=8.02e-23
 i= 880 alpha=1.000 err=0.350 loss=3.11e-23
 i= 896 alpha=1.000 err=0.338 loss=1.21e-23
 i= 912 alpha=1.000 err=0.348 loss=4.78e-24
 i= 928 alpha=1.000 err=0.340 loss=1.80e-24
 i= 944 alpha=1.000 err=0.327 loss=7.22e-25
 i= 960 alpha=1.000 err=0.330 loss=2.69e-25
 i= 976 alpha=1.000 err=0.341 loss=1.05e-25
 i= 992 alpha=1.000 err=0.332 loss=4.04e-26
 i=1008 alpha=1.000 err=0.331 loss=1.56e-26
 i=1024 alpha=1.000 err=0.340 loss=6.18e-27
 i=1040 alpha=1.000 err=0.345 loss=2.40e-27
 i=1056 alpha=1.000 err=0.352 loss=9.62e-28
 i=1072 alpha=1.000 err=0.348 loss=3.81e-28
 i=1088 alpha=1.000 err=0.340 loss=1.50e-28
 i=1104 alpha=1.000 err=0.346 loss=6.07e-29
 i=1120 alpha=1.000 err=0.338 loss=2.31e-29
 i=1136 alpha=1.000 err=0.355 loss=8.99e-30
 i=1152 alpha=1.000 err=0.334 loss=3.55e-30
 i=1168 alpha=1.000 err=0.350 loss=1.37e-30
 i=1184 alpha=1.000 err=0.353 loss=5.48e-31
 i=1200 alpha=1.000 err=0.346 loss=2.14e-31
 i=1216 alpha=1.000 err=0.340 loss=8.37e-32
 i=1232 alpha=1.000 err=0.342 loss=3.34e-32
 i=1248 alpha=1.000 err=0.327 loss=1.27e-32
 i=1264 alpha=1.000 err=0.343 loss=4.93e-33
 i=1280 alpha=1.000 err=0.344 loss=1.94e-33
 i=1296 alpha=1.000 err=0.348 loss=7.43e-34
 i=1312 alpha=1.000 err=0.342 loss=2.82e-34
 i=1328 alpha=1.000 err=0.344 loss=1.14e-34
 i=1344 alpha=1.000 err=0.328 loss=4.56e-35
 i=1360 alpha=1.000 err=0.339 loss=1.78e-35
 i=1376 alpha=1.000 err=0.340 loss=7.12e-36
 i=1392 alpha=1.000 err=0.341 loss=2.83e-36
 i=1408 alpha=1.000 err=0.348 loss=1.13e-36
 i=1424 alpha=1.000 err=0.336 loss=4.25e-37
 i=1440 alpha=1.000 err=0.348 loss=1.72e-37
 i=1456 alpha=1.000 err=0.340 loss=6.68e-38
 i=1472 alpha=1.000 err=0.338 loss=2.60e-38
 i=1488 alpha=1.000 err=0.345 loss=1.02e-38
 i=1504 alpha=1.000 err=0.350 loss=4.08e-39
 i=1520 alpha=1.000 err=0.334 loss=1.55e-39
 i=1536 alpha=1.000 err=0.350 loss=6.20e-40
 i=1552 alpha=1.000 err=0.343 loss=2.31e-40
 stopping early
Done training err=0.0000 fp=0.0000 fn=0.0000 (t=57.0s).
Done training stage 3 (time=90s).
---------------------------------------------------------------------------
Done training (time=229s).
